Theory:
Dynamic Programming Binomial Coefficients
Dynamic Programming was invented by Richard Bellman, 1950. It is a very general technique for solving optimization problems. Using Dynamic Programming requires that the problem can be divided into overlapping similar sub-problems. A recursive relation between the larger and smaller sub problems is used to fill out a table. The algorithm remembers solutions of the sub-problems and so does not have to recalculate the solutions.
Also optimal problem must have the principle of optimality (phase coined by Bellman) meaning that the optimal problem can be posed as the optimal solution among sub problems. This is not true for all optimal problems.
Dynamic Programming requires:
1. Problem divided into overlapping sub-problems
2. Sub-problem can be represented by a table
2. Principle of optimality, recursive relation between smaller and larger problems
Compared to a brute force recursive algorithm that could run exponential, the dynamic programming algorithm runs typically in quadratic time. (Recall the algorithms for the Fibonacci numbers.) The recursive algorithm ran in exponential time while the iterative algorithm ran in linear time. The space cost does increase, which is typically the size of the table. Frequently, the whole table does not have to store.
Computing a Binomial Coefficient
Computing binomial coefficients is non optimization problem but can be solved using dynamic programming.
Binomial coefficients are represented by C(n, k) or (nk) and can be used to represent the coefficients of a binomail:
(a + b)n  = C(n, 0)an + ... + C(n, k)an-kbk + ... + C(n, n)bn
The recursive relation is defined by the prior power
C(n, k) = C(n-1, k-1) + C(n-1, k) for n > k > 0
IC C(n, 0) = C(n, n) = 1
The table is then filled out iteratively, row by row using the recursive relation.
Algorithm Binomial(n, k)

for i ← 0 to n do  // fill out the table row wise

for i = 0 to min(i, k) do

if j==0 or j==i then C[i, j] ← 1  // IC

else C[i, j] ← C[i-1, j-1] + C[i-1, j]  // recursive relation

return C[n, k]
The cost of the algorithm is filing out the table. Addition is the basic operation. Because k ≤ n, the sum needs to be split into two parts because only the half the table needs to be filled out for i < k and remaining part of the table is filled out across the entire row.
A(n, k) = sum for upper triangle + sum for the lower rectangle
= ∑i=1k ∑j=1i-1 1 + ∑i=1n ∑j=1k 1
= ∑i=1k (i-1) + ∑i=1n k
= (k-1)k/2 + k(n-k) ε Θ(nk)

Note we do not need to keep the whole table, only the prior row.
We'll consider more sophisticate dynamic programming problems, Warshall's and Floyd's algorithms




def binomial_coefficient(n, k):
    # Create a 2D array to store the binomial coefficients
    C = [[0 for _ in range(k + 1)] for _ in range(n + 1)]
    
    # Calculate binomial coefficients
    for i in range(n + 1):
        for j in range(min(i, k) + 1):
            if j == 0 or j == i:
                C[i][j] = 1  # Base case: C(n, 0) = C(n, n) = 1
            else:
                C[i][j] = C[i - 1][j - 1] + C[i - 1][j]  # Recursive relation

    return C[n][k]

def main():
    n = int(input("Enter n (total elements): "))
    k = int(input("Enter k (elements to choose): "))
    
    if k > n or n < 0 or k < 0:
        print("Invalid input: Ensure that 0 <= k <= n.")
        return
    
    result = binomial_coefficient(n, k)
    
    # Output the result
    print(f"The binomial coefficient C({n}, {k}) is: {result}")


main()

# Sample Output:
# Enter n (total elements): 5
# Enter k (elements to choose): 2
# The binomial coefficient C(5, 2) is: 10
